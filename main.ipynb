{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads the content of a text file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the text file.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the file as a string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        return content\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: The file at '{file_path}' was not found.\"\n",
    "    except IOError as e:\n",
    "        return f\"Error reading file: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_paragraphs(content):\n",
    "    \"\"\"\n",
    "    Splits the given text into paragraphs.\n",
    "\n",
    "    Args:\n",
    "        content (str): The input text.\n",
    "\n",
    "    Returns:\n",
    "        list: List of paragraphs.\n",
    "    \"\"\"\n",
    "    \n",
    "    paragraphs = content.strip().split('\\n\\n')\n",
    "    \n",
    "    paragraphs = [paragraph.strip() for paragraph in paragraphs]\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_llm_summary(paragraph):\n",
    "    \"\"\"\n",
    "    Summarizes paragraph by extracting the portion of text from the beginning up to the second period.\n",
    "    This logic returns first sentence\n",
    "\n",
    "    Args:\n",
    "        paragraph (str): The input text.\n",
    "\n",
    "    Returns:\n",
    "        str: The summarized text.\n",
    "    \"\"\"  \n",
    "    \n",
    "    # Split the text by periods\n",
    "    split_by_period = paragraph.split('.')\n",
    "\n",
    "    # Check if there are at least two periods\n",
    "    if len(split_by_period) > 2:\n",
    "        paragraph_summary = '.'.join(split_by_period[:2]) + '.'\n",
    "    else:\n",
    "        # If there are fewer than two periods, return the entire paragraph\n",
    "        paragraph_summary = paragraph \n",
    "\n",
    "    return paragraph_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/regulations.txt'  \n",
    "content = read_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence – the opportunity and the challenge\n",
      "1. Artificial intelligence (AI) is already delivering wide societal benefits, from medical advances[footnote 1] to mitigating climate change.[footnote 2] For example, an AI technology developed by DeepMind, a UK-based business, can now predict the structure of almost every protein known to science.[footnote 3] This breakthrough will accelerate scientific research and the development of life-saving medicines – it has already helped scientists to make huge progress in combating malaria, antibiotic resistance, and plastic waste.\n",
      "\n",
      "2. The UK Science and Technology Framework[footnote 4] sets out government’s strategic vision and identifies AI as one of 5 critical technologies. The framework notes the role of regulation in creating the environment for AI to flourish. We know that we have yet to see AI technologies reach their full potential. Under the right conditions, AI will transform all areas of life[footnote 5] and stimulate the UK economy by unleashing innovation and driving productivity,[footnote 6] creating new jobs and improving the workplace.\n",
      "\n",
      "3. Across the world, countries and regions are beginning to draft the rules for AI. The UK needs to act quickly to continue to lead the international conversation on AI governance and demonstrate the value of our pragmatic, proportionate regulatory approach. The need to act was highlighted by Sir Patrick Vallance in his recent Regulation for Innovation review. The report identifies the short time frame for government intervention to provide a clear, pro-innovation regulatory environment in order to make the UK one of the top places in the world to build foundational AI companies.[footnote 7]\n",
      "\n",
      "4. While we should capitalise on the benefits of these technologies, we should also not overlook the new risks that may arise from their use, nor the unease that the complexity of AI technologies can produce in the wider public. We already know that some uses of AI could damage our physical[footnote 8] and mental health, [footnote 9] infringe on the privacy of individuals[footnote 10] and undermine human rights.[footnote 11]\n",
      "\n",
      "5. Public trust in AI will be undermined unless these risks, and wider concerns about the potential for bias and discrimination, are addressed. By building trust, we can accelerate the adoption of AI across the UK to maximise the economic and social benefits that the technology can deliver, while attracting investment and stimulating the creation of high-skilled AI jobs.[footnote 12] In order to maintain the UK’s position as a global AI leader, we need to ensure that the public continues to see how the benefits of AI can outweigh the risks.[footnote 13]\n",
      "\n",
      "6. Responding to risk and building public trust are important drivers for regulation. But clear and consistent regulation can also support business investment and build confidence in innovation. Throughout our extensive engagement, industry repeatedly emphasised that consumer trust is key\n",
      " to the success of innovation economies. We therefore need a clear, proportionate approach to regulation that enables the responsible application of AI to flourish. Instead of creating cumbersome rules applying to all AI technologies, our framework ensures that regulatory measures are proportionate to context and outcomes, by focusing on the use of AI rather than the technology itself.\n",
      "\n",
      "7. People and organisations develop and use AI in the UK within the rules set by our existing laws, informed by standards, guidance and other tools. But AI is a general purpose technology and its uses can cut across regulatory remits. As a result, AI technologies are currently regulated through a complex patchwork of legal requirements. We are concerned by feedback from across industry that the absence of cross-cutting AI regulation creates uncertainty and inconsistency which can undermine business and consumer confidence in AI, and stifle innovation. By providing a clear and unified approach to regulation, our framework will build public confidence, making it clear that AI technologies are subject to cross-cutting, principles-based regulation.\n",
      "\n",
      "Our pro-innovation framework\n",
      "8. The government will put in place a new framework to bring clarity and coherence to the AI regulatory landscape. This regime is designed to make responsible innovation easier. It will strengthen the UK’s position as a global leader in AI, harness AI’s ability to drive growth and prosperity,[footnote 14] and increase public trust in its use and application.\n",
      "\n",
      "9. We are taking a deliberately agile and iterative approach, recognising the speed at which these technologies are evolving. Our framework is designed to build the evidence base so that we can learn from experience and continuously adapt to develop the best possible regulatory regime. Industry has praised our pragmatic and proportionate approach.\n",
      "\n",
      "10. Our framework is underpinned by 5 principles to guide and inform the responsible development and use of AI in all sectors of the economy:\n",
      "\n",
      "Safety, security and robustness\n",
      "Appropriate transparency and explainability\n",
      "Fairness\n",
      "Accountability and governance\n",
      "Contestability and redress\n",
      "11. We will not put these principles on a statutory footing initially. New rigid and onerous legislative requirements on businesses could hold back AI innovation and reduce our ability to respond quickly and in a proportionate way to future technological advances. Instead, the principles will be issued on a non-statutory basis and implemented by existing regulators. This approach makes use of regulators’ domain-specific expertise to tailor the implementation of the principles to the specific context in which AI is used. During the initial period of implementation, we will continue to collaborate with regulators to identify any barriers to the proportionate application of the principles, and evaluate whether the non-statutory framework is having the desired effect.\n",
      "\n",
      "12. Following this initial period of implementation, and when parliamentary time allows, we anticipate introducing a statutory duty on regulators requiring them to have due regard to the principles. Some feedback from regulators, industry and academia suggested we should implement further measures to support the enforcement of the framework. A duty requiring regulators to have regard to the principles should allow regulators the flexibility to exercise judgement when applying the principles in particular contexts, while also strengthening their mandate to implement them. In line with our proposal to work collaboratively with regulators and take an adaptable approach, we will not move to introduce such a statutory duty if our monitoring of the framework shows that implementation is effective without the need to legislate.\n",
      "\n",
      "13. In the 2022 AI regulation policy paper,[footnote 15] we proposed a small coordination layer within the regulatory architecture. Industry and civil society were supportive of our intention to ensure coherence across the AI regulatory framework. However, feedback often argued strongly for greater central coordination to support regulators on issues requiring cross-cutting collaboration and ensure that the overall regulatory framework functions as intended.\n",
      "\n",
      "14. We have identified a number of central support functions required to make sure that the overall framework offers a proportionate but effective response to risk while promoting innovation across the regulatory landscape:\n",
      "\n",
      "Monitoring and evaluation of the overall regulatory framework’s effectiveness and the implementation of the principles, including the extent to which implementation supports innovation. This will allow us to remain responsive and adapt the framework if necessary, including where it needs to be adapted to remain effective in the context of developments in AI’s capabilities and the state of the art.\n",
      "Assessing and monitoring risks across the economy arising from AI.\n",
      "Conducting horizon scanning and gap analysis, including by convening industry, to inform a coherent response to emerging AI technology trends.\n",
      "Supporting testbeds and sandbox initiatives to help AI innovators get new technologies to market.\n",
      "Providing education and awareness to give clarity to businesses and empower citizens to make their voices heard as part of the ongoing iteration of the framework.\n",
      "Promoting interoperability with international regulatory frameworks.\n",
      "15. The central support functions will initially be provided from within government but will leverage existing activities and expertise from across the broader economy. The activities described above will neither replace nor duplicate the work undertaken by regulators and will not involve the creation of a new AI regulator.\n",
      "\n",
      "16. Our proportionate approach recognises that regulation is not always the most effective way to support responsible innovation. The proposed framework is aligned with, and supplemented by, a variety of tools for trustworthy AI, such as assurance techniques, voluntary guidance and technical standards. Government will promote the use of such tools. We are collaborating with partners like the UK AI Standards Hub to ensure that our overall governance framework encourages responsible AI innovation (see part 4 for details).\n",
      "\n",
      "17. In keeping with the global nature of these technologies, we will also continue to work with international partners to deliver interoperable measures that incentivise the responsible design, development and application of AI. During our call for views, industry, academia and civil society stressed that international alignment should support UK businesses to capitalise on global markets and protect UK citizens from cross-border harms.\n",
      "\n",
      "18. The UK is frequently ranked third in the world across a range of measures, including level of investment, innovation and implementation of AI.[footnote 16] To make the UK the most attractive place in the world for AI innovation and support UK companies wishing to export and attract international investment, we must ensure international compatibility between approaches. Countries around the world, as well as multilateral forums, are exploring approaches to regulating AI. Thanks to our reputation for pragmatic regulation, the UK is rightly seen by international partners as a leader in this global conversation.\n",
      "\n",
      "Part 1: Introduction\n",
      "1.1 The power and potential of artificial intelligence\n",
      "19. AI is already delivering major advances and efficiencies in many areas. AI quietly automates aspects of our everyday activities, from systems that monitor traffic to make our commutes smoother,[footnote 17] to those that detect fraud in our bank accounts.[footnote 18] AI has revolutionised large-scale safety-critical practices in industry, like controlling the process of nuclear fusion.[footnote 19] And it has also been used to accelerate scientific advancements, such as the discovery of new medicine[footnote 20] or the technologies we need to tackle climate change.[footnote 21]\n",
      "\n",
      "20. But this is just the beginning. AI can be used in a huge variety of settings and has the extraordinary potential to transform our society and economy.[footnote 22] It could have as much impact as electricity or the internet, and has been identified as one of the 5 critical technologies in the UK Science and Technology Framework.[footnote 23] As AI becomes more powerful, and as innovators explore new ways to use it, we will see more applications of AI emerge. As a result, AI has a huge potential to drive growth[footnote 24] and create jobs.[footnote 25] It will support people to carry out their existing jobs, by helping to improve workforce efficiency and workplace safety.[footnote 26] To remain world leaders in AI, attract global talent and create high-skilled jobs in the UK, we must create a regulatory environment where such innovation can thrive.\n",
      "\n",
      "21. Technological advances like large language models (LLMs) are an indication of the transformative developments yet to come.[footnote 27] LLMs provide substantial opportunities to transform the economy and society. For example, LLMs can automate the process of writing code and fixing programming bugs. The technology can support genetic medicine by identifying links between genetic sequences and medical conditions. It can support people to review and summarise key\n",
      " points from lengthy documents. In the last 4 years, LLMs have been developed beyond expectations and they are becoming applicable to an increasingly wide range of tasks.[footnote 28] We expand on the development of LLM and other foundation models in section 3.3.3 below.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paragraphs = split_text_into_paragraphs(content)\n",
    "\n",
    "for paragraph in paragraphs:\n",
    "    print(f\"{paragraph}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, paragraph in enumerate(paragraphs, 1):\n",
    "    summary_text =  simulate_llm_summary(paragraph)\n",
    "    summary_data = {\n",
    "        \"Section number\": i,\n",
    "        \"Original text\":paragraph,\n",
    "        \"Summarized requirements\":summary_text,\n",
    "        \"Source\": \"https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach/white-paper\"\n",
    "    }\n",
    "    json_output.append(summary_data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(file_path, json_output):\n",
    "    \"\"\"\n",
    "    Saves an item to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the JSON file.\n",
    "        json_output (dict): The item to save, represented as a dictionary.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Save to the file\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(json_output, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = 'data/regulations_output_summary.json' \n",
    "save_to_json(output_file_path, json_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
